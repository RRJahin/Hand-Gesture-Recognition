{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import mediapipe as mp\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = join(os.curdir, \"subsample\")\n",
    "processed_dataset_path = join(os.curdir, \"subsample_processed\")\n",
    "if not os.path.isdir(processed_dataset_path):\n",
    "    os.mkdir(processed_dataset_path)\n",
    "\n",
    "class_labels = [\n",
    "    \"call\", \"dislike\", \"fist\", \"four\", \"like\",\n",
    "    \"mute\", \"ok\", \"one\", \"palm\", \"peace\",\n",
    "    \"peace_inverted\", \"rock\", \"stop\", \"stop_inverted\",\n",
    "    \"three\", \"three2\", \"two_up\", \"two_up_inverted\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_list(path):\n",
    "    '''\n",
    "    Takes the path of a gesture and returns a 2D list containing the finger landmarks for all samples\n",
    "    '''\n",
    "    # Instantiate mediapipe hands object\n",
    "    mp_hands = mp.solutions.hands\n",
    "    # Select hand detection setting\n",
    "    with mp_hands.Hands(\n",
    "            static_image_mode=True,\n",
    "            max_num_hands=1,\n",
    "            min_detection_confidence=0.5) as hands:\n",
    "        # Define a list to store all the hand location data\n",
    "        data_list = []\n",
    "        # Iterate over each image\n",
    "        for idx, file in enumerate(path):\n",
    "            # Read image\n",
    "            image = cv2.imread(file)\n",
    "            # Convert the BGR image to RGB before processing.\n",
    "            results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            # Skip if no hand detected\n",
    "            if not results.multi_hand_landmarks:\n",
    "                continue\n",
    "            # Check if Left hand is detected\n",
    "            if results.multi_handedness[0].classification[0].label == 'Left':\n",
    "                # Flip the image\n",
    "                image = cv2.flip(image, 1)\n",
    "                # Convert the BGR image to RGB before processing\n",
    "                results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            # Skip if no hand detected\n",
    "            if not results.multi_hand_landmarks:\n",
    "                continue\n",
    "            \n",
    "            # Print handedness and draw hand landmarks on the image.\n",
    "            # print('Handedness:', results.multi_handedness)\n",
    "            \n",
    "            landmark_list = []\n",
    "            \n",
    "            for i in range(21):\n",
    "                landmark_list.append(results.multi_hand_landmarks[0].landmark[i].x)\n",
    "                landmark_list.append(results.multi_hand_landmarks[0].landmark[i].y)\n",
    "                landmark_list.append(results.multi_hand_landmarks[0].landmark[i].z)\n",
    "            \n",
    "            data_list.append(landmark_list)\n",
    "\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call: 89 samples\n",
      "dislike: 81 samples\n",
      "fist: 87 samples\n",
      "four: 92 samples\n",
      "like: 77 samples\n",
      "mute: 82 samples\n",
      "ok: 89 samples\n",
      "one: 85 samples\n",
      "palm: 91 samples\n",
      "peace: 87 samples\n",
      "peace_inverted: 98 samples\n",
      "rock: 84 samples\n",
      "stop: 88 samples\n",
      "stop_inverted: 81 samples\n",
      "three: 90 samples\n",
      "three2: 94 samples\n",
      "two_up: 86 samples\n",
      "two_up_inverted: 81 samples\n"
     ]
    }
   ],
   "source": [
    "for i, gesture in enumerate(class_labels):\n",
    "    image_path = glob(join(dataset_path, gesture, \"*jpg\"))\n",
    "    data_list = get_data_list(image_path)\n",
    "\n",
    "    with open(join(processed_dataset_path, f\"{gesture}.csv\"), \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(data_list)\n",
    "\n",
    "    print(f\"{gesture}: {len(data_list)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1562, 63)\n",
      "y shape: (1562,)\n"
     ]
    }
   ],
   "source": [
    "# Define dataset X and label y with a dummy row\n",
    "X = np.zeros((1, 63))\n",
    "y = np.zeros(1)\n",
    "# Read and concatenate data\n",
    "for i, gesture in enumerate(class_labels):\n",
    "    data = np.loadtxt(join(processed_dataset_path, f\"{gesture}.csv\"),\n",
    "                      delimiter=\",\", \n",
    "                      dtype=float)\n",
    "    label = np.full(data.shape[0], i)\n",
    "    # Concatenate into dataset and label\n",
    "    X = np.concatenate((X, data), axis=0)\n",
    "    y = np.concatenate((y, label))\n",
    "\n",
    "# Remove the dummy row from dataset X\n",
    "X = X[1:, :]\n",
    "y = y[1:]\n",
    "# Show dataset and label shape\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "# Export to csv\n",
    "np.savetxt(join(processed_dataset_path, \"X.csv\"), X, delimiter=\",\")\n",
    "np.savetxt(join(processed_dataset_path, \"y.csv\"), y, delimiter=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
